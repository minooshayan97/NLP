# HW6
## POS tagging using Transformesr
In this exercise, the goal is to pos tag sentences using the pre-trained BERT model. The given data is divided into training and
test sections, with a tag in front of each word. Finetune the pre-trained BERT model by using the data from the training section, and finally run the fine-tuned
model by labeling each sentence of the test set and its performance accuracy according to different parameters and different pre-training models. Calculate the data
(ParsBERT and multilingual models) and present the observations and results in the form of a report and compare them with the results obtained in exercise number 3.
